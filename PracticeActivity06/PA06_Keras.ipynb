{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "---\n",
    "title: \"Practice Activity 6: Keras\"\n",
    "author: \"Isabella McCarty\"\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    code-fold: true\n",
    "    theme: pulse\n",
    "    code-line-numbers: true\n",
    "    code-tools: true\n",
    "    self-contained: true\n",
    "execute:\n",
    "  message: false\n",
    "  warning: false\n",
    "---"
   ],
   "id": "555134ae3c7f0d12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Instructions\n",
    "\n",
    "Review the dataset information here: [Wine Information Dataset on Kaggle](https://www.kaggle.com/datasets/dev7halo/wine-information)\n",
    "\n",
    "### Objectives\n",
    "\n",
    "1. **Regression Task**\n",
    "   Use the dataset variables to predict wine price. Re-implement the model architecture and results you created last week.\n",
    "\n",
    "2. **Classification Task**\n",
    "   Use the dataset variables to classify the nation of origin.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "#### Neural Network Implementation\n",
    "\n",
    "* Re-implement your previous neural networks using Keras.\n",
    "* For each model:\n",
    "\n",
    "  * Print a model summary or include a model plot.\n",
    "  * Print model performance metrics using a train-test split.\n",
    "\n",
    "#### Additional Exploration\n",
    "\n",
    "* Explore at least three different Keras function input settings not used in your previous implementation.\n",
    "* Provide commentary on what you discover about these settings and how they affect the model.\n",
    "\n",
    "#### Evaluation\n",
    "\n",
    "* Report at least three different model performance metrics.\n",
    "* Construct a confusion matrix for each neural network model. You may use libraries such as `pandas`, `numpy`, or `scikit-learn`.\n",
    "\n",
    "#### Feature Constraints\n",
    "\n",
    "* Do not use any variables that explicitly identify the nation when predicting nation."
   ],
   "id": "7444103887700aca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:41:26.365854Z",
     "start_time": "2025-05-10T04:41:20.243011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn import preprocessing\n",
    "from keras import regularizers\n",
    "from itertools import product\n",
    "import random\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, confusion_matrix, precision_score, \\\n",
    "    recall_score, f1_score, roc_auc_score, roc_curve, cohen_kappa_score, make_scorer, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingRegressor, StackingRegressor, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "def set_seeds(seed=123):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ],
   "id": "eea77c510cc8e5b4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:41:26.465252Z",
     "start_time": "2025-05-10T04:41:26.382458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read in the dataset\n",
    "wine_df = pd.read_csv(\n",
    "    'Data/cleansingWine.csv', low_memory=False\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "\n",
    "\n",
    "# Display the first few rows to get a sense of the structure\n",
    "wine_df.head()"
   ],
   "id": "43bf233ec8a11e62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       id                          name      producer  nation        local1  \\\n",
       "0  137197                        Altair        Altair   Chile  Rapel Valley   \n",
       "1  137198               Altair, Sideral        Altair   Chile  Rapel Valley   \n",
       "2  137199              Baron du Val Red  Baron du Val  France           NaN   \n",
       "3  137200            Baron du Val White  Baron du Val  France           NaN   \n",
       "4  137201  Benziger, Cabernet Sauvignon      Benziger     USA    California   \n",
       "\n",
       "  local2 local3 local4          varieties1   varieties2  ...    use    abv  \\\n",
       "0    NaN    NaN    NaN  Cabernet Sauvignon    Carmenere  ...  Table  14~15   \n",
       "1    NaN    NaN    NaN  Cabernet Sauvignon       Merlot  ...  Table  14~15   \n",
       "2    NaN    NaN    NaN            Carignan     Cinsault  ...  Table  11~12   \n",
       "3    NaN    NaN    NaN            Carignan  Ugni​ blanc  ...  Table  11~12   \n",
       "4    NaN    NaN    NaN  Cabernet Sauvignon          NaN  ...  Table  13~14   \n",
       "\n",
       "  degree   sweet   acidity   body   tannin   price  year   ml  \n",
       "0  17~19  SWEET1  ACIDITY4  BODY5  TANNIN4  220000  2014  750  \n",
       "1  16~18  SWEET1  ACIDITY3  BODY4  TANNIN4  110000  2016  750  \n",
       "2  15~17  SWEET2  ACIDITY3  BODY2  TANNIN2       0     0  750  \n",
       "3   9~11  SWEET1  ACIDITY3  BODY2  TANNIN1       0     0  750  \n",
       "4  17~19  SWEET1  ACIDITY3  BODY3  TANNIN4       0  2003  750  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>producer</th>\n",
       "      <th>nation</th>\n",
       "      <th>local1</th>\n",
       "      <th>local2</th>\n",
       "      <th>local3</th>\n",
       "      <th>local4</th>\n",
       "      <th>varieties1</th>\n",
       "      <th>varieties2</th>\n",
       "      <th>...</th>\n",
       "      <th>use</th>\n",
       "      <th>abv</th>\n",
       "      <th>degree</th>\n",
       "      <th>sweet</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>tannin</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>ml</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137197</td>\n",
       "      <td>Altair</td>\n",
       "      <td>Altair</td>\n",
       "      <td>Chile</td>\n",
       "      <td>Rapel Valley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Carmenere</td>\n",
       "      <td>...</td>\n",
       "      <td>Table</td>\n",
       "      <td>14~15</td>\n",
       "      <td>17~19</td>\n",
       "      <td>SWEET1</td>\n",
       "      <td>ACIDITY4</td>\n",
       "      <td>BODY5</td>\n",
       "      <td>TANNIN4</td>\n",
       "      <td>220000</td>\n",
       "      <td>2014</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137198</td>\n",
       "      <td>Altair, Sideral</td>\n",
       "      <td>Altair</td>\n",
       "      <td>Chile</td>\n",
       "      <td>Rapel Valley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Merlot</td>\n",
       "      <td>...</td>\n",
       "      <td>Table</td>\n",
       "      <td>14~15</td>\n",
       "      <td>16~18</td>\n",
       "      <td>SWEET1</td>\n",
       "      <td>ACIDITY3</td>\n",
       "      <td>BODY4</td>\n",
       "      <td>TANNIN4</td>\n",
       "      <td>110000</td>\n",
       "      <td>2016</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137199</td>\n",
       "      <td>Baron du Val Red</td>\n",
       "      <td>Baron du Val</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carignan</td>\n",
       "      <td>Cinsault</td>\n",
       "      <td>...</td>\n",
       "      <td>Table</td>\n",
       "      <td>11~12</td>\n",
       "      <td>15~17</td>\n",
       "      <td>SWEET2</td>\n",
       "      <td>ACIDITY3</td>\n",
       "      <td>BODY2</td>\n",
       "      <td>TANNIN2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137200</td>\n",
       "      <td>Baron du Val White</td>\n",
       "      <td>Baron du Val</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carignan</td>\n",
       "      <td>Ugni​ blanc</td>\n",
       "      <td>...</td>\n",
       "      <td>Table</td>\n",
       "      <td>11~12</td>\n",
       "      <td>9~11</td>\n",
       "      <td>SWEET1</td>\n",
       "      <td>ACIDITY3</td>\n",
       "      <td>BODY2</td>\n",
       "      <td>TANNIN1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137201</td>\n",
       "      <td>Benziger, Cabernet Sauvignon</td>\n",
       "      <td>Benziger</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Table</td>\n",
       "      <td>13~14</td>\n",
       "      <td>17~19</td>\n",
       "      <td>SWEET1</td>\n",
       "      <td>ACIDITY3</td>\n",
       "      <td>BODY3</td>\n",
       "      <td>TANNIN4</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preparing Feature Sets\n",
    "\n",
    "Our first goal is to predict the price of a wine based on a subset of features from the dataset.\n",
    "\n",
    "To do this, we will:\n",
    "- Build several **Neural Networks** with different settings to test how changes in the architecture and hyperparameters affect performance. We preemptively used Keras last week, so we will build upon the 3 most successful models for our efforts this week.\n",
    "\n",
    "Our target variable is **`price`**.\n",
    "\n",
    "#### Feature Selection\n",
    "\n",
    "For simplicity and clarity, we focus on the following features for regression:\n",
    "\n",
    "- `producer`\n",
    "- `type`\n",
    "- `use`\n",
    "- `abv` (Alcohol by Volume)\n",
    "- `sweet` (Sweetness level)\n",
    "- `acidity` (Acidity level)\n",
    "- `body` (Body level)\n",
    "- `tannin` (Tannin level)\n",
    "- `year` (Vintage year)\n",
    "- `local1` (Local region)\n",
    "- `varieties1` (Grape variety)\n",
    "\n",
    "These features were chosen because they are intuitively related to wine pricing and were relatively clean after preprocessing. Adding `local1` and `varieties1` helped capture more variation in wine characteristics, leading to improved model performance."
   ],
   "id": "19c7bd5c830bf92b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:41:26.840857Z",
     "start_time": "2025-05-10T04:41:26.661301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select only the columns of interest\n",
    "features = ['producer', 'local1', 'varieties1', 'type', 'use', 'abv', 'sweet', 'acidity', 'body', 'tannin', 'year']\n",
    "target = 'price'\n",
    "\n",
    "# Make a copy of the working data\n",
    "model_data = wine_df[features + [target]].copy()\n",
    "\n",
    "# Drop any rows with missing values\n",
    "model_data = model_data.dropna()\n",
    "\n",
    "# Keep only rows where price is greater than 0\n",
    "model_data = model_data[model_data['price'] > 0]\n",
    "\n",
    "\n",
    "# Convert features to appropriate numeric types\n",
    "def clean_range(value):\n",
    "    \"\"\" Helper function to clean values like '14~15' into an average \"\"\"\n",
    "    if isinstance(value, str) and '~' in value:\n",
    "        low, high = value.split('~')\n",
    "        return (float(low) + float(high)) / 2\n",
    "    try:\n",
    "        return float(value)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "for col in ['abv', 'year']:\n",
    "    model_data[col] = model_data[col].apply(clean_range)\n",
    "\n",
    "\n",
    "# Convert categorical columns like 'sweet', 'acidity', 'body', 'tannin'\n",
    "# These are text codes like 'SWEET1', so we extract the number\n",
    "def extract_number(value):\n",
    "    \"\"\" Helper to pull numbers out of text labels \"\"\"\n",
    "    if isinstance(value, str):\n",
    "        return int(''.join(filter(str.isdigit, value)))\n",
    "    return None\n",
    "\n",
    "\n",
    "for col in ['sweet', 'acidity', 'body', 'tannin']:\n",
    "    model_data[col] = model_data[col].apply(extract_number)\n",
    "\n",
    "# Drop again any rows with missing values after cleaning\n",
    "model_data = model_data.dropna()\n",
    "\n",
    "# Separate X and y\n",
    "X = model_data[features]\n",
    "y = model_data[target]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Preprocessing: scale numeric features, one-hot encode categoricals\n",
    "categorical_features = ['producer', 'local1', 'varieties1', 'type', 'use']\n",
    "numeric_features = ['abv', 'sweet', 'acidity', 'body', 'tannin', 'year']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the preprocessor\n",
    "X_train_prep = preprocessor.fit_transform(X_train)\n",
    "X_test_prep = preprocessor.transform(X_test)\n",
    "\n",
    "# 3. Get input shape for model\n",
    "input_shape = X_train_prep.shape[1]"
   ],
   "id": "9fd6b795de4b825f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:246: UserWarning: Found unknown categories in columns [0, 1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression Modeling",
   "id": "b0d7a4e586c3af57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Model Architectures\n",
    "\n",
    "**Model 3B – Deeper Network with Bias Initialization**\n",
    "\n",
    "This model builds on a basic feedforward structure and introduces deeper learning through **two hidden layers**:\n",
    "\n",
    "* The **first layer** has 32 neurons and uses the **ReLU activation function**, which helps the network handle non-linear patterns in the data.\n",
    "* The **second layer** has 16 neurons, also with ReLU, allowing the network to further refine learned patterns.\n",
    "* A **bias initializer (`he_normal`)** is used to set initial bias values in a way that complements ReLU and speeds up early training.\n",
    "* The **final layer** outputs a single numeric value (wine price), as this is a regression task.\n",
    "\n",
    "**Model 5B – Dropout Regularization and L2 Penalty**\n",
    "\n",
    "This architecture is designed to prevent **overfitting** by regularizing the model in two ways:\n",
    "\n",
    "* The **first layer** has 32 neurons and applies **L2 regularization** (`kernel_regularizer`). This discourages overly large weights by adding a penalty to the loss function.\n",
    "* A **Dropout layer** randomly disables 30% of neurons during each training step, forcing the network to generalize rather than memorize.\n",
    "* The **second hidden layer** (16 neurons, ReLU) processes the information passed through the dropout.\n",
    "* The final output layer again predicts wine price.\n",
    "\n",
    "**Model 6B – Batch Normalization**\n",
    "\n",
    "This architecture introduces **Batch Normalization**, which stabilizes and accelerates training:\n",
    "\n",
    "* The **first hidden layer** has 64 neurons with ReLU and **zero-initialized biases**, followed by a **Batch Normalization layer**. This adjusts layer outputs so they have consistent scale and distribution, which helps the network train more reliably.\n",
    "* The **second hidden layer** has 32 neurons and applies ReLU again."
   ],
   "id": "7f3b69143736d52b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:41:26.876588Z",
     "start_time": "2025-05-10T04:41:26.871584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model Architectures\n",
    "def build_model_3B():\n",
    "    return keras.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(32, activation='relu', bias_initializer='he_normal'),\n",
    "        layers.Dense(16, activation='relu', bias_initializer='he_normal'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "def build_model_5B():\n",
    "    return keras.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(32, activation='relu', kernel_regularizer = regularizers.L2()),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "def build_model_6B():\n",
    "    return keras.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(64, activation='relu', bias_initializer='zeros'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])"
   ],
   "id": "f103300ade02522b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:41:27.083602Z",
     "start_time": "2025-05-10T04:41:26.935851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build the models\n",
    "model_3B = build_model_3B()\n",
    "model_3B.summary()"
   ],
   "id": "9ac42b53b7716ebf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │        \u001B[38;5;34m81,472\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │           \u001B[38;5;34m528\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m17\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">81,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m82,017\u001B[0m (320.38 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,017</span> (320.38 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m82,017\u001B[0m (320.38 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,017</span> (320.38 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:41:27.154156Z",
     "start_time": "2025-05-10T04:41:27.128647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_5B = build_model_5B()\n",
    "model_5B.summary()"
   ],
   "id": "7bb54bec599c8394",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │        \u001B[38;5;34m81,472\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │           \u001B[38;5;34m528\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m17\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">81,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m82,017\u001B[0m (320.38 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,017</span> (320.38 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m82,017\u001B[0m (320.38 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,017</span> (320.38 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:41:27.238689Z",
     "start_time": "2025-05-10T04:41:27.210692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_6B = build_model_6B()\n",
    "model_6B.summary()"
   ],
   "id": "e45761fd118ba77b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_2\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │       \u001B[38;5;34m162,944\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │           \u001B[38;5;34m256\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m33\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">162,944</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m165,313\u001B[0m (645.75 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">165,313</span> (645.75 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m165,185\u001B[0m (645.25 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">165,185</span> (645.25 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m128\u001B[0m (512.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Training Function:\n",
    "\n",
    "This function handles the full lifecycle of training a neural network model, evaluating it, and printing key performance results.\n",
    "\n",
    "* **Model compilation:** The model is compiled with a specified optimizer, mean squared error (`mse`) as the loss function (appropriate for regression), and tracks two additional metrics:\n",
    "\n",
    "  * Mean Absolute Error (`mae`)\n",
    "  * Mean Absolute Percentage Error (`mape`)\n",
    "* **Training process:** The model is trained on the training set using the given number of epochs and batch size.\n",
    "  A portion (20%) of the training data is reserved as a **validation set**, used to monitor performance during training.\n",
    "* **Prediction and evaluation:** After training, the model makes predictions on the test set, and we compute:\n",
    "\n",
    "  * **MSE (Mean Squared Error):** Measures the average squared difference between predictions and true values.\n",
    "  * **MAE (Mean Absolute Error):** Gives a straightforward interpretation of average error in original units.\n",
    "  * **R² (Coefficient of Determination):** Measures how well the model explains the variation in wine prices.\n",
    "* **Reporting:** Results are printed to the console, making it easy to compare different configurations later.\n",
    "\n",
    "#### Grid Search Function:\n",
    "\n",
    "This function automates the process of testing multiple neural network configurations by looping over combinations of hyperparameters:\n",
    "\n",
    "* **Inputs:**\n",
    "\n",
    "  * `model_architecture_fn`: A function that builds a model (e.g., `build_model_3B`)\n",
    "  * Lists of possible values for:\n",
    "    \n",
    "    * Batch sizes\n",
    "    * Learning rates\n",
    "    * Optimizers (`'adam'`, `'rmsprop'`)\n",
    "* **Execution:**\n",
    "\n",
    "  * For each combination of hyperparameters, it:\n",
    "\n",
    "    * Rebuilds a fresh model\n",
    "    * Initializes the chosen optimizer with the given learning rate\n",
    "    * Trains and evaluates the model using `build_and_train()`\n",
    "* **Output:**\n",
    "\n",
    "  * Results for each configuration (including MSE, MAE, and R²) are saved to a table (`pandas DataFrame`) for easy comparison and selection of the best-performing model."
   ],
   "id": "c9c6790021cf495c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:41:27.339780Z",
     "start_time": "2025-05-10T04:41:27.334330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_and_train(model, model_name, optimizer='adam', epochs=50, batch_size=32):\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae', 'mape'])\n",
    "    history = model.fit(\n",
    "        X_train_prep, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        verbose=0\n",
    "    )\n",
    "    y_pred = model.predict(X_test_prep).flatten()\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{model_name} | Epochs: {epochs} | Batch Size: {batch_size}\")\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.3f}\")\n",
    "    print(\"-\" * 40)\n",
    "    return mse, mae, r2\n",
    "\n",
    "def grid_search_nn(model_architecture_fn, model_name, epochs_list, batch_sizes_list, learning_rates_list=None, optimizer_name_list=None):\n",
    "    set_seeds(123)\n",
    "    results = []\n",
    "    if learning_rates_list is None:\n",
    "        learning_rates_list = [0.001]\n",
    "    if optimizer_name_list is None:\n",
    "        optimizer_name_list = ['adam']\n",
    "\n",
    "    for epochs, batch_size, lr, opt_name in product(epochs_list, batch_sizes_list, learning_rates_list, optimizer_name_list):\n",
    "        model = model_architecture_fn()\n",
    "        if opt_name == 'adam':\n",
    "            optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "        elif opt_name == 'rmsprop':\n",
    "            optimizer = keras.optimizers.RMSprop(learning_rate=lr)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported optimizer: {opt_name}\")\n",
    "\n",
    "        mse, mae, r2 = build_and_train(\n",
    "            model,\n",
    "            model_name=f\"{model_name} (opt={opt_name}, epochs={epochs}, batch={batch_size}, lr={lr})\",\n",
    "            optimizer=optimizer,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Optimizer\": opt_name,\n",
    "            \"Epochs\": epochs,\n",
    "            \"Batch Size\": batch_size,\n",
    "            \"Learning Rate\": lr,\n",
    "            \"MSE\": mse,\n",
    "            \"MAE\": mae,\n",
    "            \"R2\": r2\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ],
   "id": "d96c6a33986e30b5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:41:27.366787Z",
     "start_time": "2025-05-10T04:41:27.364769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs_list = [100]\n",
    "batch_sizes_list = [32, 64]\n",
    "learning_rates_list = [0.001, 0.0005]\n",
    "optimizer_name_list = ['adam', 'rmsprop']"
   ],
   "id": "6a1541b8059a8162",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:44:06.024106Z",
     "start_time": "2025-05-10T04:41:27.388910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_3B = grid_search_nn(\n",
    "    model_architecture_fn=build_model_3B,\n",
    "    model_name=\"Model 3B: Deeper\",\n",
    "    epochs_list=epochs_list,\n",
    "    batch_sizes_list=batch_sizes_list,\n",
    "    learning_rates_list=learning_rates_list,\n",
    "    optimizer_name_list=optimizer_name_list\n",
    ")"
   ],
   "id": "6199c8a29274aefc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step\n",
      "Model 3B: Deeper (opt=adam, epochs=100, batch=32, lr=0.001) | Epochs: 100 | Batch Size: 32\n",
      "Test MSE: 46935855104.00\n",
      "Test MAE: 88776.02\n",
      "Test R²: 0.236\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 868us/step\n",
      "Model 3B: Deeper (opt=rmsprop, epochs=100, batch=32, lr=0.001) | Epochs: 100 | Batch Size: 32\n",
      "Test MSE: 49585274880.00\n",
      "Test MAE: 90663.42\n",
      "Test R²: 0.193\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 592us/step\n",
      "Model 3B: Deeper (opt=adam, epochs=100, batch=32, lr=0.0005) | Epochs: 100 | Batch Size: 32\n",
      "Test MSE: 52446396416.00\n",
      "Test MAE: 97487.82\n",
      "Test R²: 0.147\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 643us/step\n",
      "Model 3B: Deeper (opt=rmsprop, epochs=100, batch=32, lr=0.0005) | Epochs: 100 | Batch Size: 32\n",
      "Test MSE: 53966786560.00\n",
      "Test MAE: 98995.15\n",
      "Test R²: 0.122\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 612us/step\n",
      "Model 3B: Deeper (opt=adam, epochs=100, batch=64, lr=0.001) | Epochs: 100 | Batch Size: 64\n",
      "Test MSE: 50390286336.00\n",
      "Test MAE: 93620.36\n",
      "Test R²: 0.180\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step\n",
      "Model 3B: Deeper (opt=rmsprop, epochs=100, batch=64, lr=0.001) | Epochs: 100 | Batch Size: 64\n",
      "Test MSE: 52249526272.00\n",
      "Test MAE: 96375.51\n",
      "Test R²: 0.150\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step\n",
      "Model 3B: Deeper (opt=adam, epochs=100, batch=64, lr=0.0005) | Epochs: 100 | Batch Size: 64\n",
      "Test MSE: 56488992768.00\n",
      "Test MAE: 95511.58\n",
      "Test R²: 0.081\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 674us/step\n",
      "Model 3B: Deeper (opt=rmsprop, epochs=100, batch=64, lr=0.0005) | Epochs: 100 | Batch Size: 64\n",
      "Test MSE: 66211241984.00\n",
      "Test MAE: 97750.60\n",
      "Test R²: -0.077\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:46:50.372040Z",
     "start_time": "2025-05-10T04:44:06.048547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_5B = grid_search_nn(\n",
    "    model_architecture_fn=build_model_5B,\n",
    "    model_name=\"Model 5B: Dropout\",\n",
    "    epochs_list=epochs_list,\n",
    "    batch_sizes_list=batch_sizes_list,\n",
    "    learning_rates_list=learning_rates_list,\n",
    "    optimizer_name_list=optimizer_name_list\n",
    ")"
   ],
   "id": "65d38cc4f5d74f6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step\n",
      "Model 5B: Dropout (opt=adam, epochs=100, batch=32, lr=0.001) | Epochs: 100 | Batch Size: 32\n",
      "Test MSE: 47509233664.00\n",
      "Test MAE: 87167.94\n",
      "Test R²: 0.227\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 653us/step\n",
      "Model 5B: Dropout (opt=rmsprop, epochs=100, batch=32, lr=0.001) | Epochs: 100 | Batch Size: 32\n",
      "Test MSE: 49630380032.00\n",
      "Test MAE: 89229.25\n",
      "Test R²: 0.192\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 653us/step\n",
      "Model 5B: Dropout (opt=adam, epochs=100, batch=32, lr=0.0005) | Epochs: 100 | Batch Size: 32\n",
      "Test MSE: 53400096768.00\n",
      "Test MAE: 97704.76\n",
      "Test R²: 0.131\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 653us/step\n",
      "Model 5B: Dropout (opt=rmsprop, epochs=100, batch=32, lr=0.0005) | Epochs: 100 | Batch Size: 32\n",
      "Test MSE: 55029374976.00\n",
      "Test MAE: 98855.98\n",
      "Test R²: 0.105\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 633us/step\n",
      "Model 5B: Dropout (opt=adam, epochs=100, batch=64, lr=0.001) | Epochs: 100 | Batch Size: 64\n",
      "Test MSE: 50241495040.00\n",
      "Test MAE: 92295.22\n",
      "Test R²: 0.183\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 653us/step\n",
      "Model 5B: Dropout (opt=rmsprop, epochs=100, batch=64, lr=0.001) | Epochs: 100 | Batch Size: 64\n",
      "Test MSE: 53038395392.00\n",
      "Test MAE: 96724.79\n",
      "Test R²: 0.137\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step\n",
      "Model 5B: Dropout (opt=adam, epochs=100, batch=64, lr=0.0005) | Epochs: 100 | Batch Size: 64\n",
      "Test MSE: 56833941504.00\n",
      "Test MAE: 94848.08\n",
      "Test R²: 0.075\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 653us/step\n",
      "Model 5B: Dropout (opt=rmsprop, epochs=100, batch=64, lr=0.0005) | Epochs: 100 | Batch Size: 64\n",
      "Test MSE: 62037520384.00\n",
      "Test MAE: 93270.67\n",
      "Test R²: -0.009\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:50:06.944914Z",
     "start_time": "2025-05-10T04:46:50.398999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_6B = grid_search_nn(\n",
    "    model_architecture_fn=build_model_6B,\n",
    "    model_name=\"Model 6B: BatchNorm\",\n",
    "    epochs_list=epochs_list,\n",
    "    batch_sizes_list=batch_sizes_list,\n",
    "    learning_rates_list=learning_rates_list,\n",
    "    optimizer_name_list=optimizer_name_list\n",
    ")"
   ],
   "id": "9bd221dba1fba1fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Model 6B: BatchNorm (opt=adam, epochs=100, batch=32, lr=0.001) | Epochs: 100 | Batch Size: 32\n",
      "Test MSE: 45039837184.00\n",
      "Test MAE: 87428.64\n",
      "Test R²: 0.267\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step\n",
      "Model 6B: BatchNorm (opt=rmsprop, epochs=100, batch=32, lr=0.001) | Epochs: 100 | Batch Size: 32\n",
      "Test MSE: 44283944960.00\n",
      "Test MAE: 86290.17\n",
      "Test R²: 0.279\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 735us/step\n",
      "Model 6B: BatchNorm (opt=adam, epochs=100, batch=32, lr=0.0005) | Epochs: 100 | Batch Size: 32\n",
      "Test MSE: 44050755584.00\n",
      "Test MAE: 93987.96\n",
      "Test R²: 0.283\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step\n",
      "Model 6B: BatchNorm (opt=rmsprop, epochs=100, batch=32, lr=0.0005) | Epochs: 100 | Batch Size: 32\n",
      "Test MSE: 43504394240.00\n",
      "Test MAE: 89132.01\n",
      "Test R²: 0.292\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 755us/step\n",
      "Model 6B: BatchNorm (opt=adam, epochs=100, batch=64, lr=0.001) | Epochs: 100 | Batch Size: 64\n",
      "Test MSE: 46150914048.00\n",
      "Test MAE: 97811.63\n",
      "Test R²: 0.249\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 757us/step\n",
      "Model 6B: BatchNorm (opt=rmsprop, epochs=100, batch=64, lr=0.001) | Epochs: 100 | Batch Size: 64\n",
      "Test MSE: 44726820864.00\n",
      "Test MAE: 93030.16\n",
      "Test R²: 0.272\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 735us/step\n",
      "Model 6B: BatchNorm (opt=adam, epochs=100, batch=64, lr=0.0005) | Epochs: 100 | Batch Size: 64\n",
      "Test MSE: 44607057920.00\n",
      "Test MAE: 79125.69\n",
      "Test R²: 0.274\n",
      "----------------------------------------\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step\n",
      "Model 6B: BatchNorm (opt=rmsprop, epochs=100, batch=64, lr=0.0005) | Epochs: 100 | Batch Size: 64\n",
      "Test MSE: 47281422336.00\n",
      "Test MAE: 75118.05\n",
      "Test R²: 0.231\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Overall Observations\n",
    "\n",
    "| Model  | Best R²   | Optimizer | LR     | Batch Size |\n",
    "| ------ | --------- | --------- | ------ | ---------- |\n",
    "| **3B** | 0.236     | adam      | 0.001  | 32         |\n",
    "| **5B** | 0.227     | adam      | 0.001  | 32         |\n",
    "| **6B** | **0.292** | rmsprop   | 0.0005 | 32         |\n",
    "\n",
    "### **Model 3B: Deeper**\n",
    "\n",
    "* Performs best with **Adam + 0.001 LR + 32 batch** (R² = 0.236).\n",
    "* Performance declines with **lower LR** (R² drops to 0.081 with 0.0005 and batch=64).\n",
    "* **RMSprop** consistently underperforms Adam here.\n",
    "\n",
    "**Conclusion**: This model is sensitive to learning rate and benefits from a moderately small batch size and a stable optimizer (Adam).\n",
    "\n",
    "### **Model 5B: Dropout Regularization**\n",
    "\n",
    "* Performs similarly to Model 3B with **Adam + 0.001 LR + 32 batch** (R² = 0.227).\n",
    "* Dropout helps reduce overfitting but slightly limits maximum achievable R².\n",
    "* **Performance degrades with larger batch sizes** and lower learning rates.\n",
    "\n",
    "**Conclusion**: Dropout helped, but not enough to beat deeper architectures without regularization.\n",
    "\n",
    "### **Model 6B: Batch Normalization**\n",
    "\n",
    "* Consistently **better R² across the board**, peaking at **0.292 with RMSprop + 0.0005 + 32 batch**.\n",
    "* **Small batch sizes (32)** and **lower learning rate (0.0005)** yielded the most stable results.\n",
    "* Both **Adam** and **RMSprop** performed well, but **RMSprop edged ahead slightly**.\n",
    "\n",
    "**Conclusion**: Batch normalization stabilizes training and boosts performance. Model 6B is the best overall model under current settings.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* **BatchNorm > Dropout > Plain deeper network**, at least in this regression task.\n",
    "* **Adam at 0.001 and RMSprop at 0.0005** are the best learning rate-optimizer combos.\n",
    "* **Batch size of 32** consistently yields better generalization than 64.\n",
    "* The highest **R² = 0.292** indicates the model explains \\~29% of variance in price, which is not perfect, but good for noisy, high-cardinality features in our wine data.\n",
    "\n"
   ],
   "id": "9f7a13cf369767af"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Classification Modeling\n",
    "\n",
    "### Feature Selection - Cannot Carry National/Regional Hints"
   ],
   "id": "5791f9aff8a4c481"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:50:06.979454Z",
     "start_time": "2025-05-10T04:50:06.974456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How many Nations are there to Predict?\n",
    "wine_df.nation.value_counts().shape[0]"
   ],
   "id": "8882df051216e33d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:50:08.225838Z",
     "start_time": "2025-05-10T04:50:07.035519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Select only the columns of interest\n",
    "features = ['name', 'producer', 'varieties1', 'type', 'use', 'abv', 'sweet', 'acidity', 'body', 'tannin', 'year']\n",
    "target = 'nation'\n",
    "\n",
    "# Make a copy of the working data\n",
    "model_data = wine_df[features + [target]].copy()\n",
    "\n",
    "# Drop any rows with missing values\n",
    "model_data = model_data.dropna()\n",
    "\n",
    "# Keep only rows where price is greater than 0 (optional for classification—only if relevant for filtering low-quality data)\n",
    "model_data = model_data[model_data['nation'].isna() != True]\n",
    "\n",
    "# Clean columns with ranges like '14~15'\n",
    "def clean_range(value):\n",
    "    if isinstance(value, str) and '~' in value:\n",
    "        low, high = value.split('~')\n",
    "        return (float(low) + float(high)) / 2\n",
    "    try:\n",
    "        return float(value)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "for col in ['abv', 'year']:\n",
    "    model_data[col] = model_data[col].apply(clean_range)\n",
    "\n",
    "# Convert coded categorical levels to integers\n",
    "def extract_number(value):\n",
    "    if isinstance(value, str):\n",
    "        return int(''.join(filter(str.isdigit, value)))\n",
    "    return None\n",
    "\n",
    "for col in ['sweet', 'acidity', 'body', 'tannin']:\n",
    "    model_data[col] = model_data[col].apply(extract_number)\n",
    "\n",
    "# Drop again any rows with missing values after cleaning\n",
    "model_data = model_data.dropna()\n",
    "\n",
    "# Separate features and label\n",
    "X = model_data[features]\n",
    "y = model_data[target]\n",
    "\n",
    "# Encode target variable (nation) as integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # Needed for sparse_categorical_crossentropy\n",
    "\n",
    "# Save class names (for inverse mapping later)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=123)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "categorical_features = ['name', 'producer', 'varieties1', 'type', 'use']\n",
    "numeric_features = ['abv', 'sweet', 'acidity', 'body', 'tannin', 'year']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Transform the data\n",
    "X_train_prep = preprocessor.fit_transform(X_train)\n",
    "X_test_prep = preprocessor.transform(X_test)\n",
    "\n",
    "# Define input shape\n",
    "input_shape = X_train_prep.shape[1]"
   ],
   "id": "9f68556659cd55b0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:246: UserWarning: Found unknown categories in columns [0, 1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Updating Model Architectures for Classifying Nation\n",
    "\n",
    "Each of the following models is a reimplementation of its regression counterpart, modified to classify wines into one of **31 possible countries of origin**. The key architectural change is the use of a **softmax activation function in the final layer**, which outputs a probability distribution across the 31 classes.\n",
    "\n",
    "**Model 3B: Deeper Network with Bias Initialization**\n",
    "\n",
    "This model uses a two-layer fully connected architecture to learn patterns in the wine data:\n",
    "\n",
    "* The first hidden layer has **32 neurons** with the **ReLU** activation function and **He-normal bias initialization**, which helps stabilize early learning.\n",
    "* The second hidden layer has **16 neurons**, also with ReLU and He-normal bias initialization.\n",
    "* The final layer has **31 neurons** with a **softmax** activation function, producing a probability for each possible nation.\n",
    "\n",
    "**Model 5B: Dropout Regularization with L2 Penalty**\n",
    "\n",
    "This model adds regularization to help prevent overfitting, which is especially important with a high number of output classes:\n",
    "\n",
    "* The first layer has **32 neurons** with ReLU activation and **L2 regularization**, which penalizes overly large weights.\n",
    "* A **Dropout layer** randomly disables 30% of neurons during training, encouraging robustness.\n",
    "* The second hidden layer has **16 neurons** with ReLU activation.\n",
    "* The final **softmax** layer outputs the probability distribution across the 31 nations.\n",
    "\n",
    "**Model 6B: Batch Normalization with Larger Capacity**\n",
    "\n",
    "This model increases the network’s depth and stability:\n",
    "\n",
    "* The first hidden layer has **64 neurons** with ReLU activation and zero-initialized biases.\n",
    "* A **Batch Normalization layer** follows, which standardizes the outputs of the previous layer and helps the network train faster and more reliably.\n",
    "* The second hidden layer has **32 neurons** with ReLU activation.\n",
    "* The output layer is a **31-unit softmax**, which enables multi-class classification.\n"
   ],
   "id": "a22a5724a7f4a677"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:50:08.238896Z",
     "start_time": "2025-05-10T04:50:08.233941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_model_3B_classification():\n",
    "    return keras.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(32, activation='relu', bias_initializer='he_normal'),\n",
    "        layers.Dense(16, activation='relu', bias_initializer='he_normal'),\n",
    "        layers.Dense(31, activation='softmax')  # 31 output classes\n",
    "    ])\n",
    "\n",
    "def build_model_5B_classification():\n",
    "    return keras.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(32, activation='relu', kernel_regularizer=regularizers.L2()),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(31, activation='softmax')  # classification head\n",
    "    ])\n",
    "\n",
    "def build_model_6B_classification():\n",
    "    return keras.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(64, activation='relu', bias_initializer='zeros'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(31, activation='softmax')  # classification head\n",
    "    ])"
   ],
   "id": "da9b7bca1ae80789",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:50:08.277422Z",
     "start_time": "2025-05-10T04:50:08.269073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def build_and_train_classification(model, model_name, optimizer='adam', epochs=50, batch_size=32):\n",
    "    # Compile with categorical loss and accuracy\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_prep, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Predict class probabilities, then get predicted class labels\n",
    "    y_pred_probs = model.predict(X_test_prep)\n",
    "    y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    acc = accuracy_score(y_test, y_pred_labels)\n",
    "    print(f\"{model_name} | Epochs: {epochs} | Batch Size: {batch_size}\")\n",
    "    print(f\"Test Accuracy: {acc:.3f}\")\n",
    "    print(\"-\" * 40)\n",
    "    return acc\n",
    "\n",
    "def grid_search_nn_classification(model_architecture_fn, model_name, epochs_list, batch_sizes_list, learning_rates_list=None, optimizer_name_list=None):\n",
    "    set_seeds(123)\n",
    "    results = []\n",
    "\n",
    "    if learning_rates_list is None:\n",
    "        learning_rates_list = [0.001]\n",
    "    if optimizer_name_list is None:\n",
    "        optimizer_name_list = ['adam']\n",
    "\n",
    "    for epochs, batch_size, lr, opt_name in product(epochs_list, batch_sizes_list, learning_rates_list, optimizer_name_list):\n",
    "        model = model_architecture_fn()\n",
    "\n",
    "        # Build optimizer\n",
    "        if opt_name == 'adam':\n",
    "            optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "        elif opt_name == 'rmsprop':\n",
    "            optimizer = keras.optimizers.RMSprop(learning_rate=lr)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported optimizer: {opt_name}\")\n",
    "\n",
    "        # Train and evaluate\n",
    "        acc = build_and_train_classification(\n",
    "            model,\n",
    "            model_name=f\"{model_name} (opt={opt_name}, epochs={epochs}, batch={batch_size}, lr={lr})\",\n",
    "            optimizer=optimizer,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Optimizer\": opt_name,\n",
    "            \"Epochs\": epochs,\n",
    "            \"Batch Size\": batch_size,\n",
    "            \"Learning Rate\": lr,\n",
    "            \"Accuracy\": acc\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "def evaluate_classification(model, X_test, y_test, class_names=None):\n",
    "    # Predict probabilities and convert to class labels\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Generate consistent list of label IDs\n",
    "    n_classes = len(class_names) if class_names is not None else len(np.unique(y_test))\n",
    "    labels = list(range(n_classes))\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names, labels=labels))\n",
    "    \n",
    "def evaluate_best_model(results_df, model_fn, X_train, y_train, X_test, y_test, class_names):\n",
    "    best_config = results_df.sort_values(\"Accuracy\", ascending=False).iloc[0]\n",
    "    best_epochs = int(best_config[\"Epochs\"])\n",
    "    best_batch = int(best_config[\"Batch Size\"])\n",
    "    best_lr = float(best_config[\"Learning Rate\"])\n",
    "    best_opt = best_config[\"Optimizer\"]\n",
    "\n",
    "    print(f\"Evaluating best model config:\\n{best_config}\\n\")\n",
    "\n",
    "    model = model_fn()\n",
    "    if best_opt == 'adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=best_lr)\n",
    "    elif best_opt == 'rmsprop':\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=best_lr)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {best_opt}\")\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=best_epochs, batch_size=best_batch, validation_split=0.2, verbose=0)\n",
    "\n",
    "    evaluate_classification(model, X_test, y_test, class_names=class_names)"
   ],
   "id": "5732896b4cc04a00",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:50:08.337356Z",
     "start_time": "2025-05-10T04:50:08.311360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_3B_classification = build_model_3B_classification()\n",
    "model_3B_classification.summary()"
   ],
   "id": "2f20770ceca49fd3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_27\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_27\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_81 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │       \u001B[38;5;34m476,960\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_82 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │           \u001B[38;5;34m528\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_83 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m31\u001B[0m)             │           \u001B[38;5;34m527\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">476,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">527</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m478,015\u001B[0m (1.82 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">478,015</span> (1.82 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m478,015\u001B[0m (1.82 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">478,015</span> (1.82 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:50:08.404294Z",
     "start_time": "2025-05-10T04:50:08.377778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_5B_classification = build_model_5B_classification()\n",
    "model_5B_classification.summary()"
   ],
   "id": "4c01595aedd5d897",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_28\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_28\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_84 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │       \u001B[38;5;34m476,960\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_85 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │           \u001B[38;5;34m528\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_86 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m31\u001B[0m)             │           \u001B[38;5;34m527\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">476,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">527</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m478,015\u001B[0m (1.82 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">478,015</span> (1.82 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m478,015\u001B[0m (1.82 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">478,015</span> (1.82 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:50:08.493769Z",
     "start_time": "2025-05-10T04:50:08.460421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_6B_classification = build_model_6B_classification()\n",
    "model_6B_classification.summary()"
   ],
   "id": "c56677dac8dfb6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_29\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_29\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_87 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │       \u001B[38;5;34m953,920\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │           \u001B[38;5;34m256\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_88 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_89 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m31\u001B[0m)             │         \u001B[38;5;34m1,023\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">953,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,023</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m957,279\u001B[0m (3.65 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">957,279</span> (3.65 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m957,151\u001B[0m (3.65 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">957,151</span> (3.65 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m128\u001B[0m (512.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:53:02.190271Z",
     "start_time": "2025-05-10T04:50:08.525433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_3B_class = grid_search_nn_classification(\n",
    "    model_architecture_fn=build_model_3B_classification,\n",
    "    model_name=\"Model 3B\",\n",
    "    epochs_list=[100],\n",
    "    batch_sizes_list=[64],\n",
    "    learning_rates_list=[0.01, 0.001],\n",
    "    optimizer_name_list=['adam', 'rmsprop']\n",
    ")"
   ],
   "id": "71bf852eec19ebf9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step  \n",
      "Model 3B (opt=adam, epochs=100, batch=64, lr=0.01) | Epochs: 100 | Batch Size: 64\n",
      "Test Accuracy: 0.929\n",
      "----------------------------------------\n",
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step  \n",
      "Model 3B (opt=rmsprop, epochs=100, batch=64, lr=0.01) | Epochs: 100 | Batch Size: 64\n",
      "Test Accuracy: 0.929\n",
      "----------------------------------------\n",
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step  \n",
      "Model 3B (opt=adam, epochs=100, batch=64, lr=0.001) | Epochs: 100 | Batch Size: 64\n",
      "Test Accuracy: 0.934\n",
      "----------------------------------------\n",
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step  \n",
      "Model 3B (opt=rmsprop, epochs=100, batch=64, lr=0.001) | Epochs: 100 | Batch Size: 64\n",
      "Test Accuracy: 0.903\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:53:02.228581Z",
     "start_time": "2025-05-10T04:53:02.221514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sort by True Multi-Class Metric!\n",
    "results_3B_class.sort_values(\"Accuracy\", ascending=False)"
   ],
   "id": "a2883f65526e6bc3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Model Optimizer  Epochs  Batch Size  Learning Rate  Accuracy\n",
       "2  Model 3B      adam     100          64          0.001  0.934178\n",
       "0  Model 3B      adam     100          64          0.010  0.928898\n",
       "1  Model 3B   rmsprop     100          64          0.010  0.928546\n",
       "3  Model 3B   rmsprop     100          64          0.001  0.903203"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3B</td>\n",
       "      <td>adam</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.934178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 3B</td>\n",
       "      <td>adam</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.928898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 3B</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.928546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 3B</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.903203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:53:45.738018Z",
     "start_time": "2025-05-10T04:53:02.284632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluate_best_model(\n",
    "    results_df=results_3B_class,\n",
    "    model_fn=build_model_3B_classification,\n",
    "    X_train=X_train_prep,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_prep,\n",
    "    y_test=y_test,\n",
    "    class_names=class_names\n",
    ")"
   ],
   "id": "8005684e21b55428",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating best model config:\n",
      "Model            Model 3B\n",
      "Optimizer            adam\n",
      "Epochs                100\n",
      "Batch Size             64\n",
      "Learning Rate       0.001\n",
      "Accuracy         0.934178\n",
      "Name: 2, dtype: object\n",
      "\n",
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step  \n",
      "Classification Report:\n",
      "\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                   Argentina       0.95      0.98      0.97        63\n",
      "                   Australia       0.94      0.90      0.92       229\n",
      "                     Austria       1.00      0.94      0.97        17\n",
      "                    Bulgaria       0.00      0.00      0.00         1\n",
      "                      Canada       0.86      0.86      0.86         7\n",
      "                       Chile       0.99      0.97      0.98       319\n",
      "                       China       0.00      0.00      0.00         2\n",
      "                     Croatia       0.00      0.00      0.00         0\n",
      "                      France       0.92      0.93      0.93       713\n",
      "                     Georgia       1.00      1.00      1.00         1\n",
      "                     Germany       0.92      0.93      0.92        58\n",
      "                      Greece       1.00      0.79      0.88        14\n",
      "                     Hungary       1.00      1.00      1.00         2\n",
      "                      Israel       1.00      1.00      1.00         1\n",
      "                       Italy       0.95      0.97      0.96       676\n",
      "                       Japan       0.00      0.00      0.00         2\n",
      "                       Korea       0.75      0.75      0.75         4\n",
      "                     Lebanon       0.00      0.00      0.00         0\n",
      "                     Moldova       0.00      0.00      0.00         1\n",
      "                 New Zealand       0.76      0.88      0.82        33\n",
      "                      Others       1.00      1.00      1.00         1\n",
      "                    Portugal       0.96      0.89      0.93        28\n",
      "                     Romania       1.00      1.00      1.00         1\n",
      "                    Slovenia       1.00      0.67      0.80         6\n",
      "                       Spain       0.91      0.95      0.93       237\n",
      "                          UK       0.00      0.00      0.00         0\n",
      "                         USA       0.93      0.93      0.93       376\n",
      "                     Uruguay       0.00      0.00      0.00         3\n",
      "the Republic of South Africa       0.88      0.78      0.83        46\n",
      "\n",
      "                    accuracy                           0.94      2841\n",
      "                   macro avg       0.68      0.66      0.67      2841\n",
      "                weighted avg       0.93      0.94      0.93      2841\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:57:05.160825Z",
     "start_time": "2025-05-10T04:53:45.763455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_5B_class = grid_search_nn_classification(\n",
    "    model_architecture_fn=build_model_5B_classification,\n",
    "    model_name=\"Model 5B\",\n",
    "    epochs_list=[100],\n",
    "    batch_sizes_list=[64],\n",
    "    learning_rates_list=[0.01, 0.001],\n",
    "    optimizer_name_list=['adam', 'rmsprop']\n",
    ")"
   ],
   "id": "6035d123e0c2224e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step  \n",
      "Model 5B (opt=adam, epochs=100, batch=64, lr=0.01) | Epochs: 100 | Batch Size: 64\n",
      "Test Accuracy: 0.803\n",
      "----------------------------------------\n",
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step  \n",
      "Model 5B (opt=rmsprop, epochs=100, batch=64, lr=0.01) | Epochs: 100 | Batch Size: 64\n",
      "Test Accuracy: 0.643\n",
      "----------------------------------------\n",
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step  \n",
      "Model 5B (opt=adam, epochs=100, batch=64, lr=0.001) | Epochs: 100 | Batch Size: 64\n",
      "Test Accuracy: 0.909\n",
      "----------------------------------------\n",
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step  \n",
      "Model 5B (opt=rmsprop, epochs=100, batch=64, lr=0.001) | Epochs: 100 | Batch Size: 64\n",
      "Test Accuracy: 0.806\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:57:05.174966Z",
     "start_time": "2025-05-10T04:57:05.167830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sort by True Multi-Class Metric!\n",
    "results_5B_class.sort_values(\"Accuracy\", ascending=False)"
   ],
   "id": "38b4d00a01e46e87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Model Optimizer  Epochs  Batch Size  Learning Rate  Accuracy\n",
       "2  Model 5B      adam     100          64          0.001  0.908835\n",
       "3  Model 5B   rmsprop     100          64          0.001  0.806054\n",
       "0  Model 5B      adam     100          64          0.010  0.802534\n",
       "1  Model 5B   rmsprop     100          64          0.010  0.643435"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 5B</td>\n",
       "      <td>adam</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.908835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 5B</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.806054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 5B</td>\n",
       "      <td>adam</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.802534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 5B</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.643435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T04:58:00.354661Z",
     "start_time": "2025-05-10T04:57:05.230619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluate_best_model(\n",
    "    results_df=results_5B_class,\n",
    "    model_fn=build_model_5B_classification,\n",
    "    X_train=X_train_prep,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_prep,\n",
    "    y_test=y_test,\n",
    "    class_names=class_names\n",
    ")"
   ],
   "id": "1ca626ab40e14d08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating best model config:\n",
      "Model            Model 5B\n",
      "Optimizer            adam\n",
      "Epochs                100\n",
      "Batch Size             64\n",
      "Learning Rate       0.001\n",
      "Accuracy         0.908835\n",
      "Name: 2, dtype: object\n",
      "\n",
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step  \n",
      "Classification Report:\n",
      "\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                   Argentina       0.95      0.98      0.97        63\n",
      "                   Australia       0.84      0.87      0.85       229\n",
      "                     Austria       0.93      0.82      0.88        17\n",
      "                    Bulgaria       0.00      0.00      0.00         1\n",
      "                      Canada       0.86      0.86      0.86         7\n",
      "                       Chile       0.97      0.97      0.97       319\n",
      "                       China       0.00      0.00      0.00         2\n",
      "                     Croatia       0.00      0.00      0.00         0\n",
      "                      France       0.85      0.96      0.90       713\n",
      "                     Georgia       0.00      0.00      0.00         1\n",
      "                     Germany       0.79      0.93      0.86        58\n",
      "                      Greece       1.00      0.50      0.67        14\n",
      "                     Hungary       0.00      0.00      0.00         2\n",
      "                      Israel       0.00      0.00      0.00         1\n",
      "                       Italy       0.96      0.93      0.95       676\n",
      "                       Japan       0.00      0.00      0.00         2\n",
      "                       Korea       0.40      0.50      0.44         4\n",
      "                     Lebanon       0.00      0.00      0.00         0\n",
      "                     Moldova       0.00      0.00      0.00         1\n",
      "                 New Zealand       0.93      0.76      0.83        33\n",
      "                      Others       0.00      0.00      0.00         1\n",
      "                    Portugal       0.80      0.86      0.83        28\n",
      "                     Romania       0.00      0.00      0.00         1\n",
      "                    Slovenia       0.00      0.00      0.00         6\n",
      "                       Spain       0.93      0.90      0.91       237\n",
      "                          UK       0.00      0.00      0.00         0\n",
      "                         USA       0.93      0.84      0.88       376\n",
      "                     Uruguay       0.00      0.00      0.00         3\n",
      "the Republic of South Africa       1.00      0.65      0.79        46\n",
      "\n",
      "                    accuracy                           0.91      2841\n",
      "                   macro avg       0.45      0.43      0.43      2841\n",
      "                weighted avg       0.90      0.91      0.90      2841\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T05:02:23.644315Z",
     "start_time": "2025-05-10T04:58:00.377121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_6B_class = grid_search_nn_classification(\n",
    "    model_architecture_fn=build_model_6B_classification,\n",
    "    model_name=\"Model 6B\",\n",
    "    epochs_list=[100],\n",
    "    batch_sizes_list=[64],\n",
    "    learning_rates_list=[0.01, 0.001],\n",
    "    optimizer_name_list=['adam', 'rmsprop']\n",
    ")"
   ],
   "id": "3c7a4744b61295e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\n",
      "Model 6B (opt=adam, epochs=100, batch=64, lr=0.01) | Epochs: 100 | Batch Size: 64\n",
      "Test Accuracy: 0.936\n",
      "----------------------------------------\n",
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "Model 6B (opt=rmsprop, epochs=100, batch=64, lr=0.01) | Epochs: 100 | Batch Size: 64\n",
      "Test Accuracy: 0.852\n",
      "----------------------------------------\n",
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\n",
      "Model 6B (opt=adam, epochs=100, batch=64, lr=0.001) | Epochs: 100 | Batch Size: 64\n",
      "Test Accuracy: 0.943\n",
      "----------------------------------------\n",
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\n",
      "Model 6B (opt=rmsprop, epochs=100, batch=64, lr=0.001) | Epochs: 100 | Batch Size: 64\n",
      "Test Accuracy: 0.936\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T05:02:23.659641Z",
     "start_time": "2025-05-10T05:02:23.653323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sort by True Multi-Class Metric!\n",
    "results_6B_class.sort_values(\"Accuracy\", ascending=False)"
   ],
   "id": "7c1b84fc304a64be",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Model Optimizer  Epochs  Batch Size  Learning Rate  Accuracy\n",
       "2  Model 6B      adam     100          64          0.001  0.943330\n",
       "3  Model 6B   rmsprop     100          64          0.001  0.935938\n",
       "0  Model 6B      adam     100          64          0.010  0.935586\n",
       "1  Model 6B   rmsprop     100          64          0.010  0.852165"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 6B</td>\n",
       "      <td>adam</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.943330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 6B</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.935938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 6B</td>\n",
       "      <td>adam</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.935586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 6B</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.852165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T05:03:29.813521Z",
     "start_time": "2025-05-10T05:02:23.718067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluate_best_model(\n",
    "    results_df=results_6B_class,\n",
    "    model_fn=build_model_6B_classification,\n",
    "    X_train=X_train_prep,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_prep,\n",
    "    y_test=y_test,\n",
    "    class_names=class_names\n",
    ")"
   ],
   "id": "a2092b195ea5cae4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating best model config:\n",
      "Model            Model 6B\n",
      "Optimizer            adam\n",
      "Epochs                100\n",
      "Batch Size             64\n",
      "Learning Rate       0.001\n",
      "Accuracy          0.94333\n",
      "Name: 2, dtype: object\n",
      "\n",
      "\u001B[1m89/89\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\n",
      "Classification Report:\n",
      "\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                   Argentina       0.97      0.98      0.98        63\n",
      "                   Australia       0.92      0.91      0.92       229\n",
      "                     Austria       1.00      0.94      0.97        17\n",
      "                    Bulgaria       0.00      0.00      0.00         1\n",
      "                      Canada       0.86      0.86      0.86         7\n",
      "                       Chile       0.95      0.98      0.96       319\n",
      "                       China       0.00      0.00      0.00         2\n",
      "                     Croatia       0.00      0.00      0.00         0\n",
      "                      France       0.91      0.95      0.93       713\n",
      "                     Georgia       1.00      1.00      1.00         1\n",
      "                     Germany       0.88      0.98      0.93        58\n",
      "                      Greece       1.00      0.79      0.88        14\n",
      "                     Hungary       1.00      1.00      1.00         2\n",
      "                      Israel       1.00      1.00      1.00         1\n",
      "                       Italy       0.99      0.96      0.97       676\n",
      "                       Japan       0.00      0.00      0.00         2\n",
      "                       Korea       0.75      0.75      0.75         4\n",
      "                     Lebanon       0.00      0.00      0.00         0\n",
      "                     Moldova       0.00      0.00      0.00         1\n",
      "                 New Zealand       0.76      0.85      0.80        33\n",
      "                      Others       1.00      1.00      1.00         1\n",
      "                    Portugal       0.96      0.93      0.95        28\n",
      "                     Romania       1.00      1.00      1.00         1\n",
      "                    Slovenia       1.00      0.67      0.80         6\n",
      "                       Spain       0.96      0.92      0.94       237\n",
      "                          UK       0.00      0.00      0.00         0\n",
      "                         USA       0.92      0.93      0.93       376\n",
      "                     Uruguay       0.00      0.00      0.00         3\n",
      "the Republic of South Africa       0.95      0.80      0.87        46\n",
      "\n",
      "                    accuracy                           0.94      2841\n",
      "                   macro avg       0.68      0.66      0.67      2841\n",
      "                weighted avg       0.94      0.94      0.94      2841\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Overall Comparison\n",
    "\n",
    "| Model  | Optimizer | LR    | Accuracy  | Notes                                                    |\n",
    "| ------ | --------- | ----- | --------- | -------------------------------------------------------- |\n",
    "| **3B** | Adam      | 0.001 | 0.934     | Strong general model, stable                             |\n",
    "| **5B** | Adam      | 0.001 | 0.909     | Dropout adds regularization but reduces top-end accuracy |\n",
    "| **6B** | Adam      | 0.001 | **0.943** | Best performer, benefits from BatchNorm                  |\n",
    "\n",
    "Model 6B (BatchNorm + Adam, 0.001 LR)** delivers the highest classification accuracy: **0.943**, and very strong per-class metrics.\n",
    "\n",
    "### **Model 3B: Deeper Network**\n",
    "\n",
    "* Performed well (0.934 accuracy) with **Adam + 0.001 LR**\n",
    "* **RMSprop degraded performance** (0.903)\n",
    "* Misclassification happens on rare classes (China, UK, Japan), but recall is high on dominant classes like France, Chile, and Italy.\n",
    "\n",
    "**Conclusion**: Stable and general-purpose; performs well but may benefit from normalization.\n",
    "\n",
    "### **Model 5B: Dropout Regularization**\n",
    "\n",
    "* Performance maxed out at **0.909 accuracy**\n",
    "* Regularization helped prevent overfitting but capped expressiveness\n",
    "* Accuracy and recall dropped on smaller classes; many minority nations had 0% recall\n",
    "\n",
    "**Conclusion**: Good for generalization, but less capable of capturing edge cases—better for noisy data but weaker on fine-grained classification.\n",
    "\n",
    "### **Model 6B: Batch Normalization**\n",
    "\n",
    "* Best performer at **0.943 accuracy**\n",
    "* Extremely strong precision/recall for dominant countries like France, Italy, and USA\n",
    "* Still struggles with **ultra-rare classes** (0 support = 0 recall, which is expected)\n",
    "\n",
    "**Conclusion**: BatchNorm boosts training stability and model capacity. Best pick when you're aiming for performance across many classes with imbalanced support.\n",
    "\n",
    "\n",
    "#### Class-Specific Highlights\n",
    "\n",
    "| Class                                | Observation                                                  |\n",
    "|--------------------------------------|--------------------------------------------------------------|\n",
    "| France, Italy, Chile, USA            | High precision + recall, dominant classes well modeled       |\n",
    "| Argentina, Germany, Portugal, Spain  | Also well predicted across all models                        |\n",
    "| China, Japan, Uruguay, UK, Moldova   | Always near 0, not enough support in training data           |\n",
    "| New Zealand, Australia, South Africa | Variable depending on model, with moderate-to-high precision |\n",
    "\n",
    "\n",
    "### Metric Summary\n",
    "\n",
    "| Metric Type | Model 3B | Model 5B | Model 6B  |\n",
    "| ----------- | -------- | -------- | --------- |\n",
    "| Accuracy    | 0.934    | 0.909    | **0.943** |\n",
    "| Macro F1    | 0.67     | 0.43     | **0.67**  |\n",
    "| Weighted F1 | 0.93     | 0.90     | **0.94**  |\n",
    "\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "* **Use Model 6B** for best performance and stability. Batch normalization gives it a significant edge, especially on major nations.\n",
    "* **Model 5B is more defensive**—good when overfitting is a risk, but not optimal when high precision is needed.\n",
    "* **Rare classes** remain a challenge; data augmentation or class weighting may help if improving those is a goal.\n"
   ],
   "id": "1dc2376cea7f3b81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f882be4053766b91"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
