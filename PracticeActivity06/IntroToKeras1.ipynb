{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Classifying Penguins with Keras"
   ],
   "metadata": {
    "id": "CVnLC9WmBfn2"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AMotUPNyzAQC",
    "ExecuteTime": {
     "end_time": "2025-05-07T17:41:06.552783Z",
     "start_time": "2025-05-07T17:41:05.560722Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, cohen_kappa_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingRegressor, StackingRegressor, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import root_mean_squared_error"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "from palmerpenguins import load_penguins\n",
    "penguins = load_penguins()\n",
    "penguins.head()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "4bOrEE7teh0-",
    "outputId": "5e34d7fb-78b2-4312-fac4-bb39bf5d4174",
    "ExecuteTime": {
     "end_time": "2025-05-07T17:41:06.576592Z",
     "start_time": "2025-05-07T17:41:06.567360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  \n",
       "3          NaN     NaN  2007  \n",
       "4       3450.0  female  2007  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "penguins_x = pd.concat([penguins[['body_mass_g', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm']], pd.get_dummies(penguins['sex'])], axis = 1)\n",
    "# penguins_x = penguins_x[['body_mass_g', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'female', 'male']]\n",
    "penguins_x"
   ],
   "metadata": {
    "id": "xGluiV08BeLq",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "outputId": "e83c3b0e-f1cc-4364-eec8-0e697285655c",
    "ExecuteTime": {
     "end_time": "2025-05-07T17:41:06.617371Z",
     "start_time": "2025-05-07T17:41:06.608188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     body_mass_g  bill_length_mm  bill_depth_mm  flipper_length_mm  female  \\\n",
       "0         3750.0            39.1           18.7              181.0   False   \n",
       "1         3800.0            39.5           17.4              186.0    True   \n",
       "2         3250.0            40.3           18.0              195.0    True   \n",
       "3            NaN             NaN            NaN                NaN   False   \n",
       "4         3450.0            36.7           19.3              193.0    True   \n",
       "..           ...             ...            ...                ...     ...   \n",
       "339       4000.0            55.8           19.8              207.0   False   \n",
       "340       3400.0            43.5           18.1              202.0    True   \n",
       "341       3775.0            49.6           18.2              193.0   False   \n",
       "342       4100.0            50.8           19.0              210.0   False   \n",
       "343       3775.0            50.2           18.7              198.0    True   \n",
       "\n",
       "      male  \n",
       "0     True  \n",
       "1    False  \n",
       "2    False  \n",
       "3    False  \n",
       "4    False  \n",
       "..     ...  \n",
       "339   True  \n",
       "340  False  \n",
       "341   True  \n",
       "342   True  \n",
       "343  False  \n",
       "\n",
       "[344 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3750.0</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3250.0</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3450.0</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>4000.0</td>\n",
       "      <td>55.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>207.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>3400.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>202.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>3775.0</td>\n",
       "      <td>49.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>4100.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>3775.0</td>\n",
       "      <td>50.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>198.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "x = penguins_x.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaled_penguins_x = pd.DataFrame(min_max_scaler.fit_transform(x), columns=penguins_x.columns)\n",
    "scaled_penguins_x"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "BLFjpDxGLcZf",
    "outputId": "06db5825-23e1-4357-c638-f5988d1f8f36",
    "ExecuteTime": {
     "end_time": "2025-05-07T17:41:06.666153Z",
     "start_time": "2025-05-07T17:41:06.656676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     body_mass_g  bill_length_mm  bill_depth_mm  flipper_length_mm  female  \\\n",
       "0       0.291667        0.254545       0.666667           0.152542     0.0   \n",
       "1       0.305556        0.269091       0.511905           0.237288     1.0   \n",
       "2       0.152778        0.298182       0.583333           0.389831     1.0   \n",
       "3            NaN             NaN            NaN                NaN     0.0   \n",
       "4       0.208333        0.167273       0.738095           0.355932     1.0   \n",
       "..           ...             ...            ...                ...     ...   \n",
       "339     0.361111        0.861818       0.797619           0.593220     0.0   \n",
       "340     0.194444        0.414545       0.595238           0.508475     1.0   \n",
       "341     0.298611        0.636364       0.607143           0.355932     0.0   \n",
       "342     0.388889        0.680000       0.702381           0.644068     0.0   \n",
       "343     0.298611        0.658182       0.666667           0.440678     1.0   \n",
       "\n",
       "     male  \n",
       "0     1.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "..    ...  \n",
       "339   1.0  \n",
       "340   0.0  \n",
       "341   1.0  \n",
       "342   1.0  \n",
       "343   0.0  \n",
       "\n",
       "[344 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.269091</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.152778</td>\n",
       "      <td>0.298182</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.389831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.167273</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.861818</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.414545</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.298611</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.298611</td>\n",
       "      <td>0.658182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "penguins_y = penguins['species']\n",
    "print(penguins_y)\n",
    "penguins_y = penguins_y.astype('category').cat.codes.to_numpy()\n",
    "penguins_y"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zPnxexh87IzR",
    "outputId": "3a76b852-8b03-4723-b9ee-09289b8ecc58",
    "ExecuteTime": {
     "end_time": "2025-05-07T17:41:06.806685Z",
     "start_time": "2025-05-07T17:41:06.799709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Adelie\n",
      "1         Adelie\n",
      "2         Adelie\n",
      "3         Adelie\n",
      "4         Adelie\n",
      "         ...    \n",
      "339    Chinstrap\n",
      "340    Chinstrap\n",
      "341    Chinstrap\n",
      "342    Chinstrap\n",
      "343    Chinstrap\n",
      "Name: species, Length: 344, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "#construct the model\n",
    "inputs = keras.Input(shape=(6,))\n",
    "x = layers.Dense(7, activation = 'relu')(inputs)\n",
    "x = layers.Dense(5, activation = 'relu')(x)\n",
    "x = layers.Dense(3, activation = 'relu')(x)\n",
    "outputs = layers.Dense(3, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"penguin_model\")"
   ],
   "metadata": {
    "id": "5A35n0kL3Fqs",
    "ExecuteTime": {
     "end_time": "2025-05-07T17:41:07.004826Z",
     "start_time": "2025-05-07T17:41:06.922840Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "SDDPXxJm4b9a",
    "outputId": "1edd88dd-1225-44e3-ba71-390cddb829a4",
    "ExecuteTime": {
     "end_time": "2025-05-07T17:41:07.205554Z",
     "start_time": "2025-05-07T17:41:07.193564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"penguin_model\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"penguin_model\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001B[38;5;33mInputLayer\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m)              │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m)              │            \u001B[38;5;34m49\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5\u001B[0m)              │            \u001B[38;5;34m40\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m)              │            \u001B[38;5;34m18\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m)              │            \u001B[38;5;34m12\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m119\u001B[0m (476.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">119</span> (476.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m119\u001B[0m (476.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">119</span> (476.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "keras.utils.plot_model(model, show_shapes = True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U83OS37y4gOY",
    "outputId": "ebbacf70-3757-4fd3-8de5-5f9709289999",
    "ExecuteTime": {
     "end_time": "2025-05-07T17:41:07.272915Z",
     "start_time": "2025-05-07T17:41:07.270049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(scaled_penguins_x, penguins_y, batch_size = 64, epochs=100, validation_split=0.1)\n",
    "\n",
    "scores = model.evaluate(scaled_penguins_x, penguins_y, verbose=2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m1t7HYuR4kSA",
    "outputId": "e4be831e-ea3a-4b47-83b5-e6f91d0200f7",
    "ExecuteTime": {
     "end_time": "2025-05-07T17:41:24.760938Z",
     "start_time": "2025-05-07T17:41:07.318341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:708: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - accuracy: 0.2281 - loss: 1.1476 - val_accuracy: 0.0000e+00 - val_loss: 1.1115\n",
      "Epoch 2/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.4085 - loss: 1.0935 - val_accuracy: 0.0000e+00 - val_loss: 1.1192\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:708: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.4940 - loss: 1.0904 - val_accuracy: 0.0000e+00 - val_loss: 1.1258\n",
      "Epoch 4/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.4802 - loss: 1.0891 - val_accuracy: 0.0000e+00 - val_loss: 1.1323\n",
      "Epoch 5/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.5131 - loss: 1.0858 - val_accuracy: 0.0000e+00 - val_loss: 1.1386\n",
      "Epoch 6/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.5134 - loss: 1.0843 - val_accuracy: 0.0000e+00 - val_loss: 1.1450\n",
      "Epoch 7/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.5090 - loss: 1.0821 - val_accuracy: 0.0000e+00 - val_loss: 1.1513\n",
      "Epoch 8/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.4997 - loss: 1.0800 - val_accuracy: 0.0000e+00 - val_loss: 1.1575\n",
      "Epoch 9/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.5201 - loss: 1.0777 - val_accuracy: 0.0000e+00 - val_loss: 1.1638\n",
      "Epoch 10/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.4901 - loss: 1.0772 - val_accuracy: 0.0000e+00 - val_loss: 1.1704\n",
      "Epoch 11/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.4956 - loss: 1.0765 - val_accuracy: 0.0000e+00 - val_loss: 1.1769\n",
      "Epoch 12/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.4917 - loss: 1.0740 - val_accuracy: 0.0000e+00 - val_loss: 1.1833\n",
      "Epoch 13/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.4838 - loss: 1.0735 - val_accuracy: 0.0000e+00 - val_loss: 1.1898\n",
      "Epoch 14/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.4934 - loss: 1.0709 - val_accuracy: 0.0000e+00 - val_loss: 1.1960\n",
      "Epoch 15/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.5069 - loss: 1.0679 - val_accuracy: 0.0000e+00 - val_loss: 1.2020\n",
      "Epoch 16/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.4977 - loss: 1.0651 - val_accuracy: 0.0000e+00 - val_loss: 1.2080\n",
      "Epoch 17/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.4867 - loss: 1.0629 - val_accuracy: 0.0000e+00 - val_loss: 1.2142\n",
      "Epoch 18/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.5231 - loss: 1.0618 - val_accuracy: 0.0000e+00 - val_loss: 1.2200\n",
      "Epoch 19/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.4786 - loss: 1.0628 - val_accuracy: 0.0000e+00 - val_loss: 1.2262\n",
      "Epoch 20/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.4862 - loss: 1.0603 - val_accuracy: 0.0000e+00 - val_loss: 1.2324\n",
      "Epoch 21/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.5049 - loss: 1.0538 - val_accuracy: 0.0000e+00 - val_loss: 1.2384\n",
      "Epoch 22/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.5259 - loss: 1.0525 - val_accuracy: 0.0000e+00 - val_loss: 1.2444\n",
      "Epoch 23/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.4806 - loss: 1.0530 - val_accuracy: 0.0000e+00 - val_loss: 1.2505\n",
      "Epoch 24/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.5021 - loss: 1.0509 - val_accuracy: 0.0000e+00 - val_loss: 1.2566\n",
      "Epoch 25/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.5131 - loss: 1.0512 - val_accuracy: 0.0000e+00 - val_loss: 1.2626\n",
      "Epoch 26/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.5301 - loss: 1.0432 - val_accuracy: 0.0000e+00 - val_loss: 1.2686\n",
      "Epoch 27/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.4921 - loss: 1.0465 - val_accuracy: 0.0000e+00 - val_loss: 1.2748\n",
      "Epoch 28/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4921 - loss: 1.0459 - val_accuracy: 0.0000e+00 - val_loss: 1.2812\n",
      "Epoch 29/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.4865 - loss: 1.0464 - val_accuracy: 0.0000e+00 - val_loss: 1.2877\n",
      "Epoch 30/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.4745 - loss: 1.0463 - val_accuracy: 0.0000e+00 - val_loss: 1.2942\n",
      "Epoch 31/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.5027 - loss: 1.0375 - val_accuracy: 0.0000e+00 - val_loss: 1.3005\n",
      "Epoch 32/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 143ms/step - accuracy: 0.4719 - loss: 1.0400 - val_accuracy: 0.0000e+00 - val_loss: 1.3066\n",
      "Epoch 33/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4845 - loss: 1.0414 - val_accuracy: 0.0000e+00 - val_loss: 1.3126\n",
      "Epoch 34/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.5069 - loss: 1.0326 - val_accuracy: 0.0000e+00 - val_loss: 1.3186\n",
      "Epoch 35/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.4708 - loss: 1.0370 - val_accuracy: 0.0000e+00 - val_loss: 1.3246\n",
      "Epoch 36/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.5242 - loss: 1.0219 - val_accuracy: 0.0000e+00 - val_loss: 1.3304\n",
      "Epoch 37/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5090 - loss: 1.0313 - val_accuracy: 0.0000e+00 - val_loss: 1.3369\n",
      "Epoch 38/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.5071 - loss: 1.0264 - val_accuracy: 0.0000e+00 - val_loss: 1.3429\n",
      "Epoch 39/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.4932 - loss: 1.0296 - val_accuracy: 0.0000e+00 - val_loss: 1.3491\n",
      "Epoch 40/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.4702 - loss: 1.0330 - val_accuracy: 0.0000e+00 - val_loss: 1.3554\n",
      "Epoch 41/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.4888 - loss: 1.0260 - val_accuracy: 0.0000e+00 - val_loss: 1.3617\n",
      "Epoch 42/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.4758 - loss: 1.0308 - val_accuracy: 0.0000e+00 - val_loss: 1.3683\n",
      "Epoch 43/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.4719 - loss: 1.0293 - val_accuracy: 0.0000e+00 - val_loss: 1.3749\n",
      "Epoch 44/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.4934 - loss: 1.0189 - val_accuracy: 0.0000e+00 - val_loss: 1.3813\n",
      "Epoch 45/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.5047 - loss: 1.0276 - val_accuracy: 0.0000e+00 - val_loss: 1.3879\n",
      "Epoch 46/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.4613 - loss: 1.0232 - val_accuracy: 0.0000e+00 - val_loss: 1.3941\n",
      "Epoch 47/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.5090 - loss: 1.0191 - val_accuracy: 0.0000e+00 - val_loss: 1.4003\n",
      "Epoch 48/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.4778 - loss: 1.0167 - val_accuracy: 0.0000e+00 - val_loss: 1.4064\n",
      "Epoch 49/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.5051 - loss: 1.0165 - val_accuracy: 0.0000e+00 - val_loss: 1.4129\n",
      "Epoch 50/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.5071 - loss: 1.0128 - val_accuracy: 0.0000e+00 - val_loss: 1.4194\n",
      "Epoch 51/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - accuracy: 0.5286 - loss: 1.0109 - val_accuracy: 0.0000e+00 - val_loss: 1.4255\n",
      "Epoch 52/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.4995 - loss: 1.0120 - val_accuracy: 0.0000e+00 - val_loss: 1.4317\n",
      "Epoch 53/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4717 - loss: 1.0228 - val_accuracy: 0.0000e+00 - val_loss: 1.4380\n",
      "Epoch 54/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.5010 - loss: 1.0048 - val_accuracy: 0.0000e+00 - val_loss: 1.4437\n",
      "Epoch 55/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4951 - loss: 1.0098 - val_accuracy: 0.0000e+00 - val_loss: 1.4498\n",
      "Epoch 56/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.4841 - loss: 1.0049 - val_accuracy: 0.0000e+00 - val_loss: 1.4560\n",
      "Epoch 57/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4882 - loss: 1.0131 - val_accuracy: 0.0000e+00 - val_loss: 1.4627\n",
      "Epoch 58/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.4691 - loss: 1.0210 - val_accuracy: 0.0000e+00 - val_loss: 1.4694\n",
      "Epoch 59/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.4600 - loss: 1.0187 - val_accuracy: 0.0000e+00 - val_loss: 1.4757\n",
      "Epoch 60/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.5092 - loss: 1.0023 - val_accuracy: 0.0000e+00 - val_loss: 1.4820\n",
      "Epoch 61/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.4878 - loss: 1.0052 - val_accuracy: 0.0000e+00 - val_loss: 1.4882\n",
      "Epoch 62/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.5021 - loss: 0.9949 - val_accuracy: 0.0000e+00 - val_loss: 1.4943\n",
      "Epoch 63/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.4895 - loss: 1.0104 - val_accuracy: 0.0000e+00 - val_loss: 1.5007\n",
      "Epoch 64/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.5116 - loss: 1.0026 - val_accuracy: 0.0000e+00 - val_loss: 1.5069\n",
      "Epoch 65/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.5042 - loss: 1.0001 - val_accuracy: 0.0000e+00 - val_loss: 1.5131\n",
      "Epoch 66/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.5270 - loss: 0.9950 - val_accuracy: 0.0000e+00 - val_loss: 1.5186\n",
      "Epoch 67/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.5190 - loss: 0.9857 - val_accuracy: 0.0000e+00 - val_loss: 1.5242\n",
      "Epoch 68/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4901 - loss: 0.9914 - val_accuracy: 0.0000e+00 - val_loss: 1.5299\n",
      "Epoch 69/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.4589 - loss: 1.0063 - val_accuracy: 0.0000e+00 - val_loss: 1.5360\n",
      "Epoch 70/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.4621 - loss: 1.0074 - val_accuracy: 0.0000e+00 - val_loss: 1.5422\n",
      "Epoch 71/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4875 - loss: 0.9901 - val_accuracy: 0.0000e+00 - val_loss: 1.5481\n",
      "Epoch 72/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4910 - loss: 0.9954 - val_accuracy: 0.0000e+00 - val_loss: 1.5542\n",
      "Epoch 73/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4919 - loss: 0.9934 - val_accuracy: 0.0000e+00 - val_loss: 1.5606\n",
      "Epoch 74/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.4917 - loss: 0.9894 - val_accuracy: 0.0000e+00 - val_loss: 1.5670\n",
      "Epoch 75/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.5160 - loss: 0.9893 - val_accuracy: 0.0000e+00 - val_loss: 1.5735\n",
      "Epoch 76/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.4869 - loss: 1.0044 - val_accuracy: 0.0000e+00 - val_loss: 1.5800\n",
      "Epoch 77/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.4960 - loss: 0.9891 - val_accuracy: 0.0000e+00 - val_loss: 1.5863\n",
      "Epoch 78/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step - accuracy: 0.4895 - loss: 0.9917 - val_accuracy: 0.0000e+00 - val_loss: 1.5928\n",
      "Epoch 79/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4589 - loss: 1.0041 - val_accuracy: 0.0000e+00 - val_loss: 1.5990\n",
      "Epoch 80/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.5064 - loss: 0.9816 - val_accuracy: 0.0000e+00 - val_loss: 1.6051\n",
      "Epoch 81/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4856 - loss: 0.9887 - val_accuracy: 0.0000e+00 - val_loss: 1.6113\n",
      "Epoch 82/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.5131 - loss: 0.9837 - val_accuracy: 0.0000e+00 - val_loss: 1.6173\n",
      "Epoch 83/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4808 - loss: 0.9841 - val_accuracy: 0.0000e+00 - val_loss: 1.6234\n",
      "Epoch 84/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.4921 - loss: 0.9753 - val_accuracy: 0.0000e+00 - val_loss: 1.6290\n",
      "Epoch 85/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4697 - loss: 0.9842 - val_accuracy: 0.0000e+00 - val_loss: 1.6349\n",
      "Epoch 86/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.4693 - loss: 1.0003 - val_accuracy: 0.0000e+00 - val_loss: 1.6410\n",
      "Epoch 87/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.4982 - loss: 0.9704 - val_accuracy: 0.0000e+00 - val_loss: 1.6465\n",
      "Epoch 88/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4882 - loss: 0.9842 - val_accuracy: 0.0000e+00 - val_loss: 1.6525\n",
      "Epoch 89/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.5045 - loss: 0.9724 - val_accuracy: 0.0000e+00 - val_loss: 1.6584\n",
      "Epoch 90/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4925 - loss: 0.9752 - val_accuracy: 0.0000e+00 - val_loss: 1.6647\n",
      "Epoch 91/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.4917 - loss: 0.9831 - val_accuracy: 0.0000e+00 - val_loss: 1.6705\n",
      "Epoch 92/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.5175 - loss: 0.9563 - val_accuracy: 0.0000e+00 - val_loss: 1.6756\n",
      "Epoch 93/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4986 - loss: 0.9722 - val_accuracy: 0.0000e+00 - val_loss: 1.6810\n",
      "Epoch 94/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.4554 - loss: 0.9978 - val_accuracy: 0.0000e+00 - val_loss: 1.6868\n",
      "Epoch 95/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.4951 - loss: 0.9770 - val_accuracy: 0.0000e+00 - val_loss: 1.6923\n",
      "Epoch 96/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.4932 - loss: 0.9792 - val_accuracy: 0.0000e+00 - val_loss: 1.6985\n",
      "Epoch 97/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4854 - loss: 0.9883 - val_accuracy: 0.0000e+00 - val_loss: 1.7042\n",
      "Epoch 98/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.5320 - loss: 0.9535 - val_accuracy: 0.0000e+00 - val_loss: 1.7091\n",
      "Epoch 99/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4719 - loss: 0.9698 - val_accuracy: 0.0000e+00 - val_loss: 1.7144\n",
      "Epoch 100/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4680 - loss: 0.9823 - val_accuracy: 0.0000e+00 - val_loss: 1.7200\n",
      "11/11 - 0s - 7ms/step - accuracy: 0.4419 - loss: 1.0506\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "model_scaled = keras.Model(inputs=inputs, outputs=outputs, name=\"penguin_model_scaled\")\n",
    "\n",
    "model_scaled.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history_scaled = model_scaled.fit(scaled_penguins_x, penguins_y, batch_size = 64, epochs = 100, validation_split = 0.1)\n",
    "\n",
    "scores = model_scaled.evaluate(scaled_penguins_x, penguins_y, verbose = 2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPx9G5kE4x5t",
    "outputId": "c8e554eb-1a5d-49cf-f67d-fcba881a15ea",
    "ExecuteTime": {
     "end_time": "2025-05-07T17:41:39.537290Z",
     "start_time": "2025-05-07T17:41:24.801444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:708: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 54ms/step - accuracy: 0.4967 - loss: 0.9761 - val_accuracy: 0.0000e+00 - val_loss: 1.7363\n",
      "Epoch 2/100\n",
      "\u001B[1m1/5\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.5000 - loss: 0.9501"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isabe\\PycharmProjects\\GSB-545\\downgradedenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:708: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.4988 - loss: 0.9706 - val_accuracy: 0.0000e+00 - val_loss: 1.7444\n",
      "Epoch 3/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.4611 - loss: 0.9790 - val_accuracy: 0.0000e+00 - val_loss: 1.7513\n",
      "Epoch 4/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.5136 - loss: 0.9623 - val_accuracy: 0.0000e+00 - val_loss: 1.7572\n",
      "Epoch 5/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.4710 - loss: 0.9642 - val_accuracy: 0.0000e+00 - val_loss: 1.7631\n",
      "Epoch 6/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5073 - loss: 0.9726 - val_accuracy: 0.0000e+00 - val_loss: 1.7690\n",
      "Epoch 7/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.5283 - loss: 0.9721 - val_accuracy: 0.0000e+00 - val_loss: 1.7745\n",
      "Epoch 8/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.4869 - loss: 0.9625 - val_accuracy: 0.0000e+00 - val_loss: 1.7800\n",
      "Epoch 9/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4986 - loss: 0.9558 - val_accuracy: 0.0000e+00 - val_loss: 1.7857\n",
      "Epoch 10/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4726 - loss: 0.9735 - val_accuracy: 0.0000e+00 - val_loss: 1.7914\n",
      "Epoch 11/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4956 - loss: 0.9757 - val_accuracy: 0.0000e+00 - val_loss: 1.7971\n",
      "Epoch 12/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.4765 - loss: 0.9708 - val_accuracy: 0.0000e+00 - val_loss: 1.8022\n",
      "Epoch 13/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.4791 - loss: 0.9768 - val_accuracy: 0.0000e+00 - val_loss: 1.8074\n",
      "Epoch 14/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.4988 - loss: 0.9516 - val_accuracy: 0.0000e+00 - val_loss: 1.8122\n",
      "Epoch 15/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4969 - loss: 0.9584 - val_accuracy: 0.0000e+00 - val_loss: 1.8174\n",
      "Epoch 16/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.5008 - loss: 0.9835 - val_accuracy: 0.0000e+00 - val_loss: 1.8227\n",
      "Epoch 17/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.5008 - loss: 0.9580 - val_accuracy: 0.0000e+00 - val_loss: 1.8273\n",
      "Epoch 18/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4917 - loss: 0.9558 - val_accuracy: 0.0000e+00 - val_loss: 1.8320\n",
      "Epoch 19/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4980 - loss: 0.9563 - val_accuracy: 0.0000e+00 - val_loss: 1.8371\n",
      "Epoch 20/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.4815 - loss: 0.9739 - val_accuracy: 0.0000e+00 - val_loss: 1.8422\n",
      "Epoch 21/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4799 - loss: 0.9700 - val_accuracy: 0.0000e+00 - val_loss: 1.8474\n",
      "Epoch 22/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.4669 - loss: 0.9687 - val_accuracy: 0.0000e+00 - val_loss: 1.8523\n",
      "Epoch 23/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4752 - loss: 0.9685 - val_accuracy: 0.0000e+00 - val_loss: 1.8574\n",
      "Epoch 24/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4875 - loss: 0.9833 - val_accuracy: 0.0000e+00 - val_loss: 1.8624\n",
      "Epoch 25/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4927 - loss: 0.9599 - val_accuracy: 0.0000e+00 - val_loss: 1.8673\n",
      "Epoch 26/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.4810 - loss: 0.9609 - val_accuracy: 0.0000e+00 - val_loss: 1.8724\n",
      "Epoch 27/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.4988 - loss: 0.9430 - val_accuracy: 0.0000e+00 - val_loss: 1.8771\n",
      "Epoch 28/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4767 - loss: 0.9757 - val_accuracy: 0.0000e+00 - val_loss: 1.8823\n",
      "Epoch 29/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4995 - loss: 0.9567 - val_accuracy: 0.0000e+00 - val_loss: 1.8875\n",
      "Epoch 30/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4782 - loss: 0.9647 - val_accuracy: 0.0000e+00 - val_loss: 1.8928\n",
      "Epoch 31/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4769 - loss: 0.9657 - val_accuracy: 0.0000e+00 - val_loss: 1.8980\n",
      "Epoch 32/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4719 - loss: 0.9676 - val_accuracy: 0.0000e+00 - val_loss: 1.9031\n",
      "Epoch 33/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4977 - loss: 0.9549 - val_accuracy: 0.0000e+00 - val_loss: 1.9082\n",
      "Epoch 34/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4875 - loss: 0.9702 - val_accuracy: 0.0000e+00 - val_loss: 1.9133\n",
      "Epoch 35/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.5140 - loss: 0.9400 - val_accuracy: 0.0000e+00 - val_loss: 1.9179\n",
      "Epoch 36/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4815 - loss: 0.9536 - val_accuracy: 0.0000e+00 - val_loss: 1.9222\n",
      "Epoch 37/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4578 - loss: 0.9817 - val_accuracy: 0.0000e+00 - val_loss: 1.9269\n",
      "Epoch 38/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5325 - loss: 0.9580 - val_accuracy: 0.0000e+00 - val_loss: 1.9311\n",
      "Epoch 39/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4949 - loss: 0.9473 - val_accuracy: 0.0000e+00 - val_loss: 1.9352\n",
      "Epoch 40/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.4758 - loss: 0.9725 - val_accuracy: 0.0000e+00 - val_loss: 1.9396\n",
      "Epoch 41/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.4721 - loss: 0.9770 - val_accuracy: 0.0000e+00 - val_loss: 1.9437\n",
      "Epoch 42/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.5118 - loss: 0.9448 - val_accuracy: 0.0000e+00 - val_loss: 1.9478\n",
      "Epoch 43/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.4817 - loss: 0.9695 - val_accuracy: 0.0000e+00 - val_loss: 1.9512\n",
      "Epoch 44/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5010 - loss: 0.9378 - val_accuracy: 0.0000e+00 - val_loss: 1.9543\n",
      "Epoch 45/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5259 - loss: 0.9387 - val_accuracy: 0.0000e+00 - val_loss: 1.9577\n",
      "Epoch 46/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.4967 - loss: 0.9610 - val_accuracy: 0.0000e+00 - val_loss: 1.9615\n",
      "Epoch 47/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4778 - loss: 0.9636 - val_accuracy: 0.0000e+00 - val_loss: 1.9658\n",
      "Epoch 48/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4691 - loss: 0.9694 - val_accuracy: 0.0000e+00 - val_loss: 1.9706\n",
      "Epoch 49/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5071 - loss: 0.9557 - val_accuracy: 0.0000e+00 - val_loss: 1.9749\n",
      "Epoch 50/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4914 - loss: 0.9683 - val_accuracy: 0.0000e+00 - val_loss: 1.9790\n",
      "Epoch 51/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4980 - loss: 0.9694 - val_accuracy: 0.0000e+00 - val_loss: 1.9831\n",
      "Epoch 52/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4990 - loss: 0.9441 - val_accuracy: 0.0000e+00 - val_loss: 1.9867\n",
      "Epoch 53/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5101 - loss: 0.9460 - val_accuracy: 0.0000e+00 - val_loss: 1.9906\n",
      "Epoch 54/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.5001 - loss: 0.9589 - val_accuracy: 0.0000e+00 - val_loss: 1.9947\n",
      "Epoch 55/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4522 - loss: 0.9783 - val_accuracy: 0.0000e+00 - val_loss: 1.9988\n",
      "Epoch 56/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.5110 - loss: 0.9559 - val_accuracy: 0.0000e+00 - val_loss: 2.0025\n",
      "Epoch 57/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4951 - loss: 0.9451 - val_accuracy: 0.0000e+00 - val_loss: 2.0055\n",
      "Epoch 58/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5075 - loss: 0.9538 - val_accuracy: 0.0000e+00 - val_loss: 2.0090\n",
      "Epoch 59/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4643 - loss: 0.9606 - val_accuracy: 0.0000e+00 - val_loss: 2.0125\n",
      "Epoch 60/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.5027 - loss: 0.9459 - val_accuracy: 0.0000e+00 - val_loss: 2.0163\n",
      "Epoch 61/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.4786 - loss: 0.9517 - val_accuracy: 0.0000e+00 - val_loss: 2.0202\n",
      "Epoch 62/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4893 - loss: 0.9659 - val_accuracy: 0.0000e+00 - val_loss: 2.0233\n",
      "Epoch 63/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4901 - loss: 0.9614 - val_accuracy: 0.0000e+00 - val_loss: 2.0268\n",
      "Epoch 64/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.4765 - loss: 0.9537 - val_accuracy: 0.0000e+00 - val_loss: 2.0302\n",
      "Epoch 65/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4500 - loss: 0.9849 - val_accuracy: 0.0000e+00 - val_loss: 2.0337\n",
      "Epoch 66/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4867 - loss: 0.9566 - val_accuracy: 0.0000e+00 - val_loss: 2.0370\n",
      "Epoch 67/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5034 - loss: 0.9634 - val_accuracy: 0.0000e+00 - val_loss: 2.0404\n",
      "Epoch 68/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.4969 - loss: 0.9522 - val_accuracy: 0.0000e+00 - val_loss: 2.0436\n",
      "Epoch 69/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4847 - loss: 0.9519 - val_accuracy: 0.0000e+00 - val_loss: 2.0470\n",
      "Epoch 70/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4782 - loss: 0.9774 - val_accuracy: 0.0000e+00 - val_loss: 2.0510\n",
      "Epoch 71/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.4758 - loss: 0.9765 - val_accuracy: 0.0000e+00 - val_loss: 2.0538\n",
      "Epoch 72/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4808 - loss: 0.9545 - val_accuracy: 0.0000e+00 - val_loss: 2.0566\n",
      "Epoch 73/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.5121 - loss: 0.9525 - val_accuracy: 0.0000e+00 - val_loss: 2.0598\n",
      "Epoch 74/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4882 - loss: 0.9561 - val_accuracy: 0.0000e+00 - val_loss: 2.0629\n",
      "Epoch 75/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.5090 - loss: 0.9569 - val_accuracy: 0.0000e+00 - val_loss: 2.0664\n",
      "Epoch 76/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4897 - loss: 0.9600 - val_accuracy: 0.0000e+00 - val_loss: 2.0699\n",
      "Epoch 77/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4873 - loss: 0.9604 - val_accuracy: 0.0000e+00 - val_loss: 2.0733\n",
      "Epoch 78/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.4934 - loss: 0.9525 - val_accuracy: 0.0000e+00 - val_loss: 2.0761\n",
      "Epoch 79/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5181 - loss: 0.9496 - val_accuracy: 0.0000e+00 - val_loss: 2.0793\n",
      "Epoch 80/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4912 - loss: 0.9428 - val_accuracy: 0.0000e+00 - val_loss: 2.0822\n",
      "Epoch 81/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5114 - loss: 0.9453 - val_accuracy: 0.0000e+00 - val_loss: 2.0850\n",
      "Epoch 82/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.5097 - loss: 0.9501 - val_accuracy: 0.0000e+00 - val_loss: 2.0882\n",
      "Epoch 83/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4736 - loss: 0.9650 - val_accuracy: 0.0000e+00 - val_loss: 2.0915\n",
      "Epoch 84/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.5201 - loss: 0.9562 - val_accuracy: 0.0000e+00 - val_loss: 2.0944\n",
      "Epoch 85/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.4474 - loss: 0.9917 - val_accuracy: 0.0000e+00 - val_loss: 2.0970\n",
      "Epoch 86/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.4930 - loss: 0.9533 - val_accuracy: 0.0000e+00 - val_loss: 2.0995\n",
      "Epoch 87/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.4860 - loss: 0.9442 - val_accuracy: 0.0000e+00 - val_loss: 2.1016\n",
      "Epoch 88/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.4923 - loss: 0.9663 - val_accuracy: 0.0000e+00 - val_loss: 2.1045\n",
      "Epoch 89/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.4834 - loss: 0.9643 - val_accuracy: 0.0000e+00 - val_loss: 2.1071\n",
      "Epoch 90/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.5116 - loss: 0.9418 - val_accuracy: 0.0000e+00 - val_loss: 2.1097\n",
      "Epoch 91/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.5099 - loss: 0.9521 - val_accuracy: 0.0000e+00 - val_loss: 2.1128\n",
      "Epoch 92/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4758 - loss: 0.9778 - val_accuracy: 0.0000e+00 - val_loss: 2.1150\n",
      "Epoch 93/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4717 - loss: 0.9612 - val_accuracy: 0.0000e+00 - val_loss: 2.1174\n",
      "Epoch 94/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4799 - loss: 0.9473 - val_accuracy: 0.0000e+00 - val_loss: 2.1195\n",
      "Epoch 95/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.5138 - loss: 0.9357 - val_accuracy: 0.0000e+00 - val_loss: 2.1214\n",
      "Epoch 96/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5138 - loss: 0.9264 - val_accuracy: 0.0000e+00 - val_loss: 2.1233\n",
      "Epoch 97/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4784 - loss: 0.9597 - val_accuracy: 0.0000e+00 - val_loss: 2.1253\n",
      "Epoch 98/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4971 - loss: 0.9428 - val_accuracy: 0.0000e+00 - val_loss: 2.1271\n",
      "Epoch 99/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.4925 - loss: 0.9745 - val_accuracy: 0.0000e+00 - val_loss: 2.1288\n",
      "Epoch 100/100\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4810 - loss: 0.9480 - val_accuracy: 0.0000e+00 - val_loss: 2.1306\n",
      "11/11 - 0s - 6ms/step - accuracy: 0.4419 - loss: 1.0746\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "model_scaled.predict(scaled_penguins_x)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDO_9jIyBNJX",
    "outputId": "ce2cc348-ce63-42f4-94c0-b7e1192b7b47",
    "ExecuteTime": {
     "end_time": "2025-05-07T17:41:39.801514Z",
     "start_time": "2025-05-07T17:41:39.585991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6453127 , 0.30792508, 0.59707636],\n",
       "       [0.6453127 , 0.30792508, 0.59707636],\n",
       "       [0.6453127 , 0.30792508, 0.59707636],\n",
       "       ...,\n",
       "       [0.6453127 , 0.30792508, 0.59707636],\n",
       "       [0.6453127 , 0.30792508, 0.59707636],\n",
       "       [0.6453127 , 0.30792508, 0.59707636]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "penguins['species']"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "5badmod9DJh_",
    "outputId": "b5c64cc3-f3f9-4d08-f13b-45476a2d0ca6",
    "ExecuteTime": {
     "end_time": "2025-05-07T17:41:39.833522Z",
     "start_time": "2025-05-07T17:41:39.826526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Adelie\n",
       "1         Adelie\n",
       "2         Adelie\n",
       "3         Adelie\n",
       "4         Adelie\n",
       "         ...    \n",
       "339    Chinstrap\n",
       "340    Chinstrap\n",
       "341    Chinstrap\n",
       "342    Chinstrap\n",
       "343    Chinstrap\n",
       "Name: species, Length: 344, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "penguins_y"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P603JjtqDd_9",
    "outputId": "a8f4622a-ead9-432a-98d9-1c1d5edc835c",
    "ExecuteTime": {
     "end_time": "2025-05-07T17:41:39.890183Z",
     "start_time": "2025-05-07T17:41:39.884184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  }
 ]
}
